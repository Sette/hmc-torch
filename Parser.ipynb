{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ecb52a-eafe-48b6-a816-2582938ab995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cc3cbd7-5e7d-45c5-973e-0079efde72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "from hmc.utils import create_dir, __load_json__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e4ff68-230e-4084-8a2b-053016db3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'enron_others': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/others/Enron_corr_trainvalid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/others/Enron_corr_test.arff'\n",
    "    ),\n",
    "    'diatoms_others': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/others/Diatoms_train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/others/Diatoms_test.arff'\n",
    "    ),\n",
    "    'imclef07a_others': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/others/ImCLEF07A_Train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/others/ImCLEF07A_Test.arff'\n",
    "    ),\n",
    "    'imclef07d_others': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/others/ImCLEF07D_Train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/others/ImCLEF07D_Test.arff'\n",
    "    ),\n",
    "    'cellcycle_FUN': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/cellcycle_FUN/cellcycle_FUN.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/cellcycle_FUN/cellcycle_FUN.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/cellcycle_FUN/cellcycle_FUN.test.arff'\n",
    "    ),\n",
    "    'derisi_FUN': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/derisi_FUN/derisi_FUN.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/derisi_FUN/derisi_FUN.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/derisi_FUN/derisi_FUN.test.arff'\n",
    "    ),\n",
    "    'eisen_FUN': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/eisen_FUN/eisen_FUN.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/eisen_FUN/eisen_FUN.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/eisen_FUN/eisen_FUN.test.arff'\n",
    "    ),\n",
    "    'expr_FUN': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/expr_FUN/expr_FUN.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/expr_FUN/expr_FUN.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/expr_FUN/expr_FUN.test.arff'\n",
    "    ),\n",
    "    'gasch1_FUN': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/gasch1_FUN/gasch1_FUN.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/gasch1_FUN/gasch1_FUN.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/gasch1_FUN/gasch1_FUN.test.arff'\n",
    "    ),\n",
    "    'gasch2_FUN': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/gasch2_FUN/gasch2_FUN.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/gasch2_FUN/gasch2_FUN.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/gasch2_FUN/gasch2_FUN.test.arff'\n",
    "    ),\n",
    "    'seq_FUN': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/seq_FUN/seq_FUN.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/seq_FUN/seq_FUN.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/seq_FUN/seq_FUN.test.arff'\n",
    "    ),\n",
    "    'spo_FUN': (\n",
    "        False,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/spo_FUN/spo_FUN.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/spo_FUN/spo_FUN.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_FUN/spo_FUN/spo_FUN.test.arff'\n",
    "    ),\n",
    "    'cellcycle_GO': (\n",
    "        True,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/cellcycle_GO/cellcycle_GO.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/cellcycle_GO/cellcycle_GO.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/cellcycle_GO/cellcycle_GO.test.arff'\n",
    "    ),\n",
    "    'derisi_GO': (\n",
    "        True,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/derisi_GO/derisi_GO.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/derisi_GO/derisi_GO.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/derisi_GO/derisi_GO.test.arff'\n",
    "    ),\n",
    "    'eisen_GO': (\n",
    "        True,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/eisen_GO/eisen_GO.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/eisen_GO/eisen_GO.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/eisen_GO/eisen_GO.test.arff'\n",
    "    ),\n",
    "    'expr_GO': (\n",
    "        True,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/expr_GO/expr_GO.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/expr_GO/expr_GO.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/expr_GO/expr_GO.test.arff'\n",
    "    ),\n",
    "    'gasch1_GO': (\n",
    "        True,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/gasch1_GO/gasch1_GO.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/gasch1_GO/gasch1_GO.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/gasch1_GO/gasch1_GO.test.arff'\n",
    "    ),\n",
    "    'gasch2_GO': (\n",
    "        True,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/gasch2_GO/gasch2_GO.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/gasch2_GO/gasch2_GO.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/gasch2_GO/gasch2_GO.test.arff'\n",
    "    ),\n",
    "    'seq_GO': (\n",
    "        True,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/seq_GO/seq_GO.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/seq_GO/seq_GO.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/seq_GO/seq_GO.test.arff'\n",
    "    ),\n",
    "    'spo_GO': (\n",
    "        True,\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/spo_GO/spo_GO.train.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/spo_GO/spo_GO.valid.arff',\n",
    "        os.environ['DATA_FOLDER'] + '/HMC_data/datasets_GO/spo_GO/spo_GO.test.arff'\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9c915f9-f7d4-44a9-8a39-2d3582548911",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATA_FOLDER\"] = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "385a1b0e-cd4c-41c2-90aa-1079ea2bb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_example(data):\n",
    "    features, labels = data\n",
    "    example = {\n",
    "        'features': features,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f11707f1-09df-4ffd-bfb9-c081599e286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arff_data_to_csv():\n",
    "    def __init__(self, arff_file,  is_GO, output_path):\n",
    "        self.arrf_file = arff_file\n",
    "        self.output_path = output_path\n",
    "        create_dir(self.output_path)\n",
    "        self.csv_file = '/'.join(arff_file.split('/')[-3:]).replace('.arff', '.csv')\n",
    "        self.X, self.Y = parse_arff_to_csv(arff_file=arff_file, output_path=self.output_path , is_GO=is_GO)\n",
    "        r_, c_ = np.where(np.isnan(self.X))\n",
    "        m = np.nanmean(self.X, axis=0)\n",
    "        for i, j in zip(r_, c_):\n",
    "            self.X[i][j] = m[j]\n",
    "\n",
    "    def to_csv(self, output_file):\n",
    "        \"\"\"Salva X e Y como um arquivo CSV.\"\"\"\n",
    "        # Criando DataFrame para X\n",
    "        output_path = '/'.join(output_file.split('/')[:-1])\n",
    "        create_dir(output_path)\n",
    "\n",
    "        df_X = pd.DataFrame({'features': [json.dumps(x) for x in self.X]})\n",
    "        #df_X = pd.DataFrame({'features': json.dumps(self.X)})\n",
    "        #df_X = pd.DataFrame({'features': json.dumps(self.X)})\n",
    "        # Criando DataFrame para Y, convertendo para int se necess√°rio\n",
    "        df_Y = pd.DataFrame({'labels':self.Y})\n",
    "\n",
    "        # Concatenando X e Y\n",
    "        df = pd.concat([df_X, df_Y], axis=1)\n",
    "\n",
    "        # Salvando como CSV\n",
    "        df.to_csv(output_file, sep='|' , index=False)\n",
    "        print(f\"CSV salvo em: {output_file}\")\n",
    "\n",
    "\n",
    "    def to_pt(self, output_path):\n",
    "        \"\"\"Salva X e Y como um arquivo pt.\"\"\"\n",
    "        # Criando DataFrame para X\n",
    "        create_dir(output_path)\n",
    "        batch_size = 1024 * 50  # 50k records from each file batch\n",
    "        count = 0\n",
    "        total = math.ceil(len(self.X) / batch_size)\n",
    "        for i in range(0, len(self.X), batch_size):\n",
    "            batch_X = self.X[i:i + batch_size]\n",
    "            batch_Y = self.Y[i:i + batch_size]\n",
    "            pt_records = [create_example(data) for data in zip(batch_X, batch_Y)]\n",
    "            path = f\"{output_path}/{str(count).zfill(10)}.pt\"\n",
    "\n",
    "            torch.save(pt_records, path)\n",
    "\n",
    "            print(f\"{count} {len(pt_records)} {path}\")\n",
    "            count += 1\n",
    "            print(f\"{count}/{total} batches / {count * batch_size} processed\")\n",
    "\n",
    "        print(f\"{count}/{total} batches / {len(self.X)} processed\")\n",
    "\n",
    "\n",
    "def parse_arff_to_csv(arff_file, output_path, is_GO=False):\n",
    "    with open(arff_file) as f:\n",
    "        read_data = False\n",
    "        X = []\n",
    "        Y = []\n",
    "\n",
    "        feature_types = []\n",
    "        d = []\n",
    "        cats_lens = []\n",
    "        all_terms = []\n",
    "        for num_line, l in enumerate(f):\n",
    "            if l.startswith('@ATTRIBUTE'):\n",
    "                if l.startswith('@ATTRIBUTE class'):\n",
    "                    h = l.split('hierarchical')[1].strip()\n",
    "                    for branch in h.split(','):\n",
    "                        branch = branch.replace('/', '.')\n",
    "                        all_terms.append(branch)\n",
    "\n",
    "                else:\n",
    "                    _, f_name, f_type = l.split()\n",
    "\n",
    "                    if f_type == 'numeric' or f_type == 'NUMERIC':\n",
    "                        d.append([])\n",
    "                        cats_lens.append(1)\n",
    "                        feature_types.append(lambda x, i: [float(x)] if x != '?' else [np.nan])\n",
    "\n",
    "                    else:\n",
    "                        cats = f_type[1:-1].split(',')\n",
    "                        cats_lens.append(len(cats))\n",
    "                        d.append({key: keras.utils.to_categorical(i, len(cats)).tolist() for i, key in enumerate(cats)})\n",
    "                        feature_types.append(lambda x, i: d[i].get(x, [0.0] * cats_lens[i]))\n",
    "            elif l.startswith('@DATA'):\n",
    "                read_data = True\n",
    "            elif read_data:\n",
    "                d_line = l.split('%')[0].strip().split(',')\n",
    "                lab = d_line[len(feature_types)].replace('/', '.').strip()\n",
    "\n",
    "                X.append(list(chain(*[feature_types[i](x, i) for i, x in enumerate(d_line[:len(feature_types)])])))\n",
    "\n",
    "                #for t in lab.split('@'):\n",
    "                #    y_[[nodes_idx.get(a) for a in nx.ancestors(g_t, t.replace('/', '.'))]] = 1\n",
    "                #    y_[nodes_idx[t.replace('/', '.')]] = 1\n",
    "                Y.append(lab)\n",
    "        #X = np.array(X)\n",
    "        #Y = np.stack(Y)\n",
    "        categories = {'labels': all_terms}\n",
    "        if 'train' in arff_file:\n",
    "            labels_path = '/'.join(arff_file.split('/')[:-1])\n",
    "            dataset_path =  os.path.join(output_path, '/'.join(labels_path.split('/')[-2:]))\n",
    "            create_dir(dataset_path)\n",
    "            labels_file = os.path.join(dataset_path, 'labels.json')\n",
    "            with open(labels_file, 'w+') as f:\n",
    "                f.write(json.dumps(categories))\n",
    "        #np.save('all_terms.npy', np.array(all_terms))\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e1238fc-27da-4875-a91e-2c81d084df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dataset_arff_tocsv(name, datasets, output_path):\n",
    "    is_GO, train, val, test = datasets[name]\n",
    "    return arff_data_to_csv(train, is_GO, output_path), arff_data_to_csv(val, is_GO, output_path), arff_data_to_csv(test, is_GO, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e64a7232-7b39-452c-9178-6f5d003e001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'seq_FUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08783457-f9ea-49db-8e18-5f934216f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.environ[\"DATA_FOLDER\"]\n",
    "output_path = os.path.join(data_path, 'HMC_data_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ceeaced-aa93-4281-92f1-afb6ef6bfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = initialize_dataset_arff_tocsv(dataset_name, datasets, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27ce2e90-273c-4821-a175-7692daba5663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1701 ./HMC_data_csv/train/0000000000.pt\n",
      "1/1 batches / 51200 processed\n",
      "1/1 batches / 1701 processed\n",
      "0 879 ./HMC_data_csv/val/0000000000.pt\n",
      "1/1 batches / 51200 processed\n",
      "1/1 batches / 879 processed\n",
      "0 1339 ./HMC_data_csv/test/0000000000.pt\n",
      "1/1 batches / 51200 processed\n",
      "1/1 batches / 1339 processed\n"
     ]
    }
   ],
   "source": [
    "train.to_pt(os.path.join(output_path, 'train'))\n",
    "val.to_pt(os.path.join(output_path, 'val'))\n",
    "test.to_pt(os.path.join(output_path, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4740b6a6-b2ef-4f8f-b46a-4f6f3e2d7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./HMC_data_csv/datasets_FUN/seq_FUN/seq_FUN.test.csv',  sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23cfe3cd-5213-4a66-87e3-a51ee89bef16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4.8, 0.7, 3.1, 3.6, 3.9, 5.5, 1.4, 6.0, 8.0, ...</td>\n",
       "      <td>01.03.16@10.01.05@10.01.09.03@11.04.03.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5.2, 0.5, 3.6, 2.3, 6.5, 6.5, 1.4, 7.7, 7.9, ...</td>\n",
       "      <td>10.01.05.03.05@10.01.09.03@11.04.03.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4.3, 1.1, 2.5, 2.2, 5.7, 6.3, 2.4, 9.2, 6.0, ...</td>\n",
       "      <td>10.01.05.03.05@10.01.09.03@11.04.03.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5.7, 1.0, 2.1, 1.3, 9.4, 6.5, 3.4, 10.4, 1.8,...</td>\n",
       "      <td>02.11@02.13.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2.9, 1.2, 3.3, 2.3, 5.4, 5.0, 1.9, 11.4, 8.9,...</td>\n",
       "      <td>11.04.03.01@16.03.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>[3.2, 0.0, 7.6, 8.3, 2.5, 4.5, 1.3, 7.6, 5.1, ...</td>\n",
       "      <td>11.02.03.01@11.02.03.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>[8.1, 1.4, 6.0, 4.6, 5.1, 4.9, 2.3, 5.7, 4.0, ...</td>\n",
       "      <td>14.07.11.01@14.13.01.01@18.02.01.01.01@20.09.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>[3.5, 1.2, 2.3, 8.1, 5.8, 7.0, 2.3, 4.7, 4.7, ...</td>\n",
       "      <td>11.04.03.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>[2.6, 0.5, 5.8, 5.4, 3.3, 4.9, 3.0, 5.3, 5.8, ...</td>\n",
       "      <td>14.04@14.07.11.01@14.13.01@16.01@20.09.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>[4.5, 0.6, 9.6, 5.8, 6.4, 5.8, 1.3, 5.8, 9.0, ...</td>\n",
       "      <td>10.01.09.05@14.07.04@42.10.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1339 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               features  \\\n",
       "0     [4.8, 0.7, 3.1, 3.6, 3.9, 5.5, 1.4, 6.0, 8.0, ...   \n",
       "1     [5.2, 0.5, 3.6, 2.3, 6.5, 6.5, 1.4, 7.7, 7.9, ...   \n",
       "2     [4.3, 1.1, 2.5, 2.2, 5.7, 6.3, 2.4, 9.2, 6.0, ...   \n",
       "3     [5.7, 1.0, 2.1, 1.3, 9.4, 6.5, 3.4, 10.4, 1.8,...   \n",
       "4     [2.9, 1.2, 3.3, 2.3, 5.4, 5.0, 1.9, 11.4, 8.9,...   \n",
       "...                                                 ...   \n",
       "1334  [3.2, 0.0, 7.6, 8.3, 2.5, 4.5, 1.3, 7.6, 5.1, ...   \n",
       "1335  [8.1, 1.4, 6.0, 4.6, 5.1, 4.9, 2.3, 5.7, 4.0, ...   \n",
       "1336  [3.5, 1.2, 2.3, 8.1, 5.8, 7.0, 2.3, 4.7, 4.7, ...   \n",
       "1337  [2.6, 0.5, 5.8, 5.4, 3.3, 4.9, 3.0, 5.3, 5.8, ...   \n",
       "1338  [4.5, 0.6, 9.6, 5.8, 6.4, 5.8, 1.3, 5.8, 9.0, ...   \n",
       "\n",
       "                                                 labels  \n",
       "0             01.03.16@10.01.05@10.01.09.03@11.04.03.01  \n",
       "1                10.01.05.03.05@10.01.09.03@11.04.03.01  \n",
       "2                10.01.05.03.05@10.01.09.03@11.04.03.01  \n",
       "3                                        02.11@02.13.03  \n",
       "4                                  11.04.03.01@16.03.03  \n",
       "...                                                 ...  \n",
       "1334                            11.02.03.01@11.02.03.04  \n",
       "1335  14.07.11.01@14.13.01.01@18.02.01.01.01@20.09.0...  \n",
       "1336                                        11.04.03.01  \n",
       "1337          14.04@14.07.11.01@14.13.01@16.01@20.09.13  \n",
       "1338                      10.01.09.05@14.07.04@42.10.03  \n",
       "\n",
       "[1339 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb0242-5e46-4ac6-bb79-63542aa5e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dump = json.dumps(train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12666c9d-7247-4198-9d1b-eb897bceee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['features'] = df['features'].apply(json.loads)  # Agora funcionar√°\n",
    "\n",
    "X = df['features'].tolist()  # Se quiser lista\n",
    "# ou diretamente em NumPy\n",
    "X = np.array(df['features'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "494f97d7-3167-4cb5-8b3d-6f8dfd048483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8, 0.7, 3.1, ..., 0. , 0. , 1. ],\n",
       "       [5.2, 0.5, 3.6, ..., 0. , 0. , 1. ],\n",
       "       [4.3, 1.1, 2.5, ..., 0. , 0. , 1. ],\n",
       "       ...,\n",
       "       [3.5, 1.2, 2.3, ..., 0. , 1. , 0. ],\n",
       "       [2.6, 0.5, 5.8, ..., 0. , 1. , 0. ],\n",
       "       [4.5, 0.6, 9.6, ..., 0. , 1. , 0. ]], shape=(1339, 529))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320ea56-2d02-487d-ba27-ff1a0117ece5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
